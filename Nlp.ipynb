{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_html = urllib.request.urlopen('https://en.wikipedia.org/wiki/Cuisine')\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
    "\n",
    "article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "article_text = ''\n",
    "\n",
    "for para in article_paragraphs:\n",
    "    article_text += para.text\n",
    "\n",
    "article_text = article_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "article_text = re.sub(r'\\s+', ' ', article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentences = nltk.sent_tokenize(article_text)\n",
    "article_words = nltk.word_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_inputs = (\"hey\", \"good morning\", \"good evening\", \"morning\", \"evening\", \"hi\", \"whatsup\")\n",
    "greeting_responses = [\"hey\", \"hey hows you?\", \"*nods*\", \"hello, how you doing\", \"hello\", \"Welcome, I am good and you\"]\n",
    "\n",
    "def generate_greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    bot_response = ''\n",
    "    article_sentences.append(user_input)\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
    "    all_word_vectors = word_vectorizer.fit_transform(article_sentences)\n",
    "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "\n",
    "    matched_vector = similar_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched == 0:\n",
    "        bot_response = bot_response + \"I am sorry, I could not understand you\"\n",
    "        return bot_response\n",
    "    else:\n",
    "        bot_response = bot_response + article_sentences[similar_sentence_number]\n",
    "        return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am your friend CuisineBot. You can ask me any question regarding Cuisine:\n",
      "asian\n",
      "CuisineBot: spices at central market in agadir, morocco due to asia's vast size and extremely diverse geography and demographics, asian cuisines are many and varied, and include east asian cuisine, south asian cuisine, southeast asian cuisine, central asian cuisine and west asian cuisine.\n",
      "american\n",
      "CuisineBot: the regional cuisines are north american cuisine, mexican cuisine, central american cuisine, south american cuisine, and caribbean cuisine.\n",
      "indian\n",
      "CuisineBot: traditional north indian vegetarian thali with various curries from india.\n",
      "stop\n",
      "CuisineBot: I am sorry, I could not understand you\n",
      "\n",
      "CuisineBot: I am sorry, I could not understand you\n",
      "bye\n",
      "CuisineBot: Good bye and take care of yourself...\n"
     ]
    }
   ],
   "source": [
    "continue_dialogue = True\n",
    "print(\"Hello, I am your friend CuisineBot. You can ask me any question regarding Cuisine:\")\n",
    "while(continue_dialogue == True):\n",
    "    human_text = input()\n",
    "    human_text = human_text.lower()\n",
    "    if human_text != 'bye':\n",
    "        if human_text == 'thanks' or human_text == 'thank you very much' or human_text == 'thank you':\n",
    "            continue_dialogue = False\n",
    "            print(\"CuisineBot: Most welcome\")\n",
    "        else:\n",
    "            if generate_greeting_response(human_text) != None:\n",
    "                print(\"CuisineBot: \" + generate_greeting_response(human_text))\n",
    "            else:\n",
    "                print(\"CuisineBot: \", end=\"\")\n",
    "                print(generate_response(human_text))\n",
    "                article_sentences.remove(human_text)\n",
    "    else:\n",
    "        continue_dialogue = False\n",
    "        print(\"CuisineBot: Good bye and take care of yourself...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e75a6b090b66acafd367a5bf30cbbd02cbe2615bb5a801047227a22cd01ee66a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
